{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71297346",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import common packages\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d6d59176",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 64\n",
    "C_i, C_o = 3, 6\n",
    "H, W = 28, 28\n",
    "K = 5\n",
    "dtype=torch.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "673976b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 1\n",
    "# C_i, C_o = 1, 1\n",
    "# H, W = 2, 2\n",
    "# K = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "21628cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 3, 28, 28]), torch.Size([6, 3, 5, 5]), torch.Size([6]))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_feats = torch.rand((N, C_i, H, W), dtype=dtype)\n",
    "weight = torch.rand((C_o, C_i, K, K))\n",
    "bias = torch.rand(C_o)\n",
    "stride = 1\n",
    "padding = 0\n",
    "kernel_size = weight.size(2)\n",
    "\n",
    "input_feats.shape, weight.shape, bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "04fc7a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 6, 24, 24]), torch.Size([6, 3, 5, 5]), torch.Size([6]))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import Conv2d\n",
    "\n",
    "conv2d = Conv2d(C_i, C_o, kernel_size, stride=stride, padding=padding, dtype=dtype)\n",
    "\n",
    "conv2d_output = conv2d(input_feats)\n",
    "\n",
    "weight = torch.clone(conv2d.weight)\n",
    "bias = torch.clone(conv2d.bias)\n",
    "\n",
    "conv2d_output.shape, weight.shape, bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5c7661f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.nn.functional import fold, unfold\n",
    "\n",
    "# input_feats[0, :, :5, :5][0, 1, 0], unfold(input_feats[0, :, :5, :5], kernel_size)[5, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3d0e934c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 75, 576]),\n",
       " torch.Size([6, 75]),\n",
       " torch.Size([64, 6, 576]),\n",
       " torch.Size([64, 6, 24, 24]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.functional import fold, unfold\n",
    "\n",
    "input_unfolded = unfold(input_feats, kernel_size, padding=padding, stride=stride)\n",
    "weight_unfolded = weight.view(C_o, -1)\n",
    "\n",
    "output_unfolded = weight_unfolded @ input_unfolded\n",
    "if bias is not None:\n",
    "    output_unfolded += bias.view(-1, 1)\n",
    "H_o = (H + 2 * padding - kernel_size) // stride + 1\n",
    "output = output_unfolded.view(N, C_o, H_o, -1)\n",
    "\n",
    "input_unfolded.shape, weight_unfolded.shape, output_unfolded.shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "34fe99c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "for i, (x, y) in enumerate(zip(output.flatten(), conv2d_output.flatten())):\n",
    "    if not math.isclose(x.item(), y.item()):\n",
    "        print(i, x.item(), y.item())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2399c749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.functional import fold, unfold\n",
    "\n",
    "input_feats = torch.tensor([[[[1, 2], [3, 4]], [[5, 6], [7, 8]]]], dtype=torch.float64)\n",
    "unfold(input_feats, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0928b52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 24)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_o, W_o = output.size(2), output.size(3)\n",
    "\n",
    "H_o, W_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "9809b6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 64\n",
    "C_i, C_o = 3, 6\n",
    "H, W = 28, 28\n",
    "K = 5\n",
    "dtype=torch.float64\n",
    "padding = 0\n",
    "stride = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e36a97e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 1\n",
    "# C_i, C_o = 1, 1\n",
    "# H, W = 1, 1\n",
    "# K = 1\n",
    "# dtype=torch.float64\n",
    "# padding = 0\n",
    "# stride = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "80731140",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "input_feats = torch.rand((N, C_i, H, W), dtype=dtype)\n",
    "kernel_size = K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "115c1548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Conv2d\n",
    "\n",
    "conv2d = Conv2d(C_i, C_o, kernel_size, padding=padding, stride=stride, dtype=dtype)\n",
    "weight = torch.clone(conv2d.weight)\n",
    "bias = torch.clone(conv2d.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "49b02b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[18440.4801, 18469.7358, 18466.8721, 18451.5637, 18451.9761],\n",
       "           [18453.1814, 18475.4890, 18472.2463, 18459.1552, 18455.8155],\n",
       "           [18452.8338, 18479.6673, 18474.2342, 18471.7449, 18469.8156],\n",
       "           [18469.9589, 18493.1058, 18492.5274, 18485.5500, 18482.8736],\n",
       "           [18483.2240, 18503.7942, 18505.1529, 18503.4853, 18501.9564]],\n",
       " \n",
       "          [[18459.0968, 18460.5930, 18454.0254, 18456.0020, 18462.5861],\n",
       "           [18449.8066, 18451.7519, 18449.0025, 18453.2529, 18455.9310],\n",
       "           [18442.6837, 18441.5760, 18429.1081, 18446.9385, 18447.6622],\n",
       "           [18454.9040, 18459.6661, 18451.6285, 18462.9197, 18460.1363],\n",
       "           [18451.6130, 18456.9143, 18454.4624, 18475.3149, 18472.0842]],\n",
       " \n",
       "          [[18411.8377, 18397.1826, 18388.4731, 18391.7583, 18378.3028],\n",
       "           [18403.8543, 18395.1834, 18394.3676, 18391.7302, 18369.1994],\n",
       "           [18380.8593, 18375.9233, 18375.8145, 18370.1944, 18351.2029],\n",
       "           [18364.2336, 18358.7732, 18349.6057, 18348.0267, 18333.5251],\n",
       "           [18371.7708, 18372.8976, 18372.3837, 18368.2352, 18356.6581]]],\n",
       " \n",
       " \n",
       "         [[[18440.4801, 18469.7358, 18466.8721, 18451.5637, 18451.9761],\n",
       "           [18453.1814, 18475.4890, 18472.2463, 18459.1552, 18455.8155],\n",
       "           [18452.8338, 18479.6673, 18474.2342, 18471.7449, 18469.8156],\n",
       "           [18469.9589, 18493.1058, 18492.5274, 18485.5500, 18482.8736],\n",
       "           [18483.2240, 18503.7942, 18505.1529, 18503.4853, 18501.9564]],\n",
       " \n",
       "          [[18459.0968, 18460.5930, 18454.0254, 18456.0020, 18462.5861],\n",
       "           [18449.8066, 18451.7519, 18449.0025, 18453.2529, 18455.9310],\n",
       "           [18442.6837, 18441.5760, 18429.1081, 18446.9385, 18447.6622],\n",
       "           [18454.9040, 18459.6661, 18451.6285, 18462.9197, 18460.1363],\n",
       "           [18451.6130, 18456.9143, 18454.4624, 18475.3149, 18472.0842]],\n",
       " \n",
       "          [[18411.8377, 18397.1826, 18388.4731, 18391.7583, 18378.3028],\n",
       "           [18403.8543, 18395.1834, 18394.3676, 18391.7302, 18369.1994],\n",
       "           [18380.8593, 18375.9233, 18375.8145, 18370.1944, 18351.2029],\n",
       "           [18364.2336, 18358.7732, 18349.6057, 18348.0267, 18333.5251],\n",
       "           [18371.7708, 18372.8976, 18372.3837, 18368.2352, 18356.6581]]],\n",
       " \n",
       " \n",
       "         [[[18440.4801, 18469.7358, 18466.8721, 18451.5637, 18451.9761],\n",
       "           [18453.1814, 18475.4890, 18472.2463, 18459.1552, 18455.8155],\n",
       "           [18452.8338, 18479.6673, 18474.2342, 18471.7449, 18469.8156],\n",
       "           [18469.9589, 18493.1058, 18492.5274, 18485.5500, 18482.8736],\n",
       "           [18483.2240, 18503.7942, 18505.1529, 18503.4853, 18501.9564]],\n",
       " \n",
       "          [[18459.0968, 18460.5930, 18454.0254, 18456.0020, 18462.5861],\n",
       "           [18449.8066, 18451.7519, 18449.0025, 18453.2529, 18455.9310],\n",
       "           [18442.6837, 18441.5760, 18429.1081, 18446.9385, 18447.6622],\n",
       "           [18454.9040, 18459.6661, 18451.6285, 18462.9197, 18460.1363],\n",
       "           [18451.6130, 18456.9143, 18454.4624, 18475.3149, 18472.0842]],\n",
       " \n",
       "          [[18411.8377, 18397.1826, 18388.4731, 18391.7583, 18378.3028],\n",
       "           [18403.8543, 18395.1834, 18394.3676, 18391.7302, 18369.1994],\n",
       "           [18380.8593, 18375.9233, 18375.8145, 18370.1944, 18351.2029],\n",
       "           [18364.2336, 18358.7732, 18349.6057, 18348.0267, 18333.5251],\n",
       "           [18371.7708, 18372.8976, 18372.3837, 18368.2352, 18356.6581]]],\n",
       " \n",
       " \n",
       "         [[[18440.4801, 18469.7358, 18466.8721, 18451.5637, 18451.9761],\n",
       "           [18453.1814, 18475.4890, 18472.2463, 18459.1552, 18455.8155],\n",
       "           [18452.8338, 18479.6673, 18474.2342, 18471.7449, 18469.8156],\n",
       "           [18469.9589, 18493.1058, 18492.5274, 18485.5500, 18482.8736],\n",
       "           [18483.2240, 18503.7942, 18505.1529, 18503.4853, 18501.9564]],\n",
       " \n",
       "          [[18459.0968, 18460.5930, 18454.0254, 18456.0020, 18462.5861],\n",
       "           [18449.8066, 18451.7519, 18449.0025, 18453.2529, 18455.9310],\n",
       "           [18442.6837, 18441.5760, 18429.1081, 18446.9385, 18447.6622],\n",
       "           [18454.9040, 18459.6661, 18451.6285, 18462.9197, 18460.1363],\n",
       "           [18451.6130, 18456.9143, 18454.4624, 18475.3149, 18472.0842]],\n",
       " \n",
       "          [[18411.8377, 18397.1826, 18388.4731, 18391.7583, 18378.3028],\n",
       "           [18403.8543, 18395.1834, 18394.3676, 18391.7302, 18369.1994],\n",
       "           [18380.8593, 18375.9233, 18375.8145, 18370.1944, 18351.2029],\n",
       "           [18364.2336, 18358.7732, 18349.6057, 18348.0267, 18333.5251],\n",
       "           [18371.7708, 18372.8976, 18372.3837, 18368.2352, 18356.6581]]],\n",
       " \n",
       " \n",
       "         [[[18440.4801, 18469.7358, 18466.8721, 18451.5637, 18451.9761],\n",
       "           [18453.1814, 18475.4890, 18472.2463, 18459.1552, 18455.8155],\n",
       "           [18452.8338, 18479.6673, 18474.2342, 18471.7449, 18469.8156],\n",
       "           [18469.9589, 18493.1058, 18492.5274, 18485.5500, 18482.8736],\n",
       "           [18483.2240, 18503.7942, 18505.1529, 18503.4853, 18501.9564]],\n",
       " \n",
       "          [[18459.0968, 18460.5930, 18454.0254, 18456.0020, 18462.5861],\n",
       "           [18449.8066, 18451.7519, 18449.0025, 18453.2529, 18455.9310],\n",
       "           [18442.6837, 18441.5760, 18429.1081, 18446.9385, 18447.6622],\n",
       "           [18454.9040, 18459.6661, 18451.6285, 18462.9197, 18460.1363],\n",
       "           [18451.6130, 18456.9143, 18454.4624, 18475.3149, 18472.0842]],\n",
       " \n",
       "          [[18411.8377, 18397.1826, 18388.4731, 18391.7583, 18378.3028],\n",
       "           [18403.8543, 18395.1834, 18394.3676, 18391.7302, 18369.1994],\n",
       "           [18380.8593, 18375.9233, 18375.8145, 18370.1944, 18351.2029],\n",
       "           [18364.2336, 18358.7732, 18349.6057, 18348.0267, 18333.5251],\n",
       "           [18371.7708, 18372.8976, 18372.3837, 18368.2352, 18356.6581]]],\n",
       " \n",
       " \n",
       "         [[[18440.4801, 18469.7358, 18466.8721, 18451.5637, 18451.9761],\n",
       "           [18453.1814, 18475.4890, 18472.2463, 18459.1552, 18455.8155],\n",
       "           [18452.8338, 18479.6673, 18474.2342, 18471.7449, 18469.8156],\n",
       "           [18469.9589, 18493.1058, 18492.5274, 18485.5500, 18482.8736],\n",
       "           [18483.2240, 18503.7942, 18505.1529, 18503.4853, 18501.9564]],\n",
       " \n",
       "          [[18459.0968, 18460.5930, 18454.0254, 18456.0020, 18462.5861],\n",
       "           [18449.8066, 18451.7519, 18449.0025, 18453.2529, 18455.9310],\n",
       "           [18442.6837, 18441.5760, 18429.1081, 18446.9385, 18447.6622],\n",
       "           [18454.9040, 18459.6661, 18451.6285, 18462.9197, 18460.1363],\n",
       "           [18451.6130, 18456.9143, 18454.4624, 18475.3149, 18472.0842]],\n",
       " \n",
       "          [[18411.8377, 18397.1826, 18388.4731, 18391.7583, 18378.3028],\n",
       "           [18403.8543, 18395.1834, 18394.3676, 18391.7302, 18369.1994],\n",
       "           [18380.8593, 18375.9233, 18375.8145, 18370.1944, 18351.2029],\n",
       "           [18364.2336, 18358.7732, 18349.6057, 18348.0267, 18333.5251],\n",
       "           [18371.7708, 18372.8976, 18372.3837, 18368.2352, 18356.6581]]]],\n",
       "        dtype=torch.float64),\n",
       " tensor([36864., 36864., 36864., 36864., 36864., 36864.], dtype=torch.float64))"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.weight.grad, conv2d.bias.grad = None, None\n",
    "conv2d_output = conv2d(input_feats)\n",
    "conv2d_loss = torch.sum(conv2d_output)\n",
    "conv2d_loss.backward()\n",
    "\n",
    "conv2d.weight.grad, conv2d.bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "bd0df4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 75, 576]),\n",
       " torch.Size([6, 75]),\n",
       " torch.Size([64, 6, 576]),\n",
       " torch.Size([64, 6, 24, 24]))"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Forward\n",
    "input_unfolded = unfold(input_feats, kernel_size, padding=padding, stride=stride)\n",
    "weight_unfolded = weight.view(C_o, -1)\n",
    "\n",
    "output_unfolded = weight_unfolded @ input_unfolded\n",
    "if bias is not None:\n",
    "    output_unfolded += bias.view(-1, 1)\n",
    "H_o = (H + 2 * padding - kernel_size) // stride + 1\n",
    "output = output_unfolded.view(N, C_o, H_o, -1)\n",
    "\n",
    "input_unfolded.shape, weight_unfolded.shape, output_unfolded.shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "cc0a2cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check output\n",
    "\n",
    "import math\n",
    "for i, (x, y) in enumerate(zip(output.flatten(), conv2d_output.flatten())):\n",
    "    if not math.isclose(x.item(), y.item()):\n",
    "        print(i, x.item(), y.item())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "7052aeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_input_unfolded.shape=torch.Size([64, 75, 576])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 6, 576]),\n",
       " torch.Size([64, 576, 75]),\n",
       " torch.Size([64, 6, 75]),\n",
       " torch.Size([6, 192, 5, 5]),\n",
       " torch.Size([6]),\n",
       " torch.Size([64, 75, 576]),\n",
       " torch.Size([64, 3, 28, 28]))"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Backward\n",
    "\n",
    "from torch.nn.functional import fold, unfold\n",
    "\n",
    "H_o, W_o = output.size(2), output.size(3)\n",
    "grad_output = torch.ones(N, C_o, H_o, W_o, dtype=dtype)\n",
    "grad_output_unfolded = grad_output.view(N, C_o, -1)\n",
    "input_transpose = torch.transpose(input_unfolded, 1, 2)\n",
    "\n",
    "grad_weight_unfolded = grad_output_unfolded @ input_transpose\n",
    "grad_weight = grad_weight_unfolded.view(C_o, -1, kernel_size, kernel_size)\n",
    "\n",
    "if bias is not None:\n",
    "    grad_bias = grad_output.sum((0, 2, 3))\n",
    "    \n",
    "grad_input_unfolded = weight_unfolded.T @ grad_output_unfolded\n",
    "print(f'{grad_input_unfolded.shape=}')\n",
    "grad_input = fold(grad_input_unfolded, (H, W), kernel_size, padding=padding, stride=stride)\n",
    "\n",
    "grad_output_unfolded.shape, input_transpose.shape, grad_weight_unfolded.shape, grad_weight.shape, grad_bias.shape, grad_input_unfolded.shape, grad_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd62ea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_weight, grad_bias"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
