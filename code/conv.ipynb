{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71297346",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import common packages\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6d59176",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 64\n",
    "C_i, C_o = 3, 6\n",
    "H, W = 28, 28\n",
    "K = 5\n",
    "dtype=torch.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "673976b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 1\n",
    "# C_i, C_o = 1, 1\n",
    "# H, W = 2, 2\n",
    "# K = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21628cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 3, 28, 28]), torch.Size([6, 3, 5, 5]), torch.Size([6]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_feats = torch.rand((N, C_i, H, W), dtype=dtype)\n",
    "weight = torch.rand((C_o, C_i, K, K))\n",
    "bias = torch.rand(C_o)\n",
    "stride = 1\n",
    "padding = 0\n",
    "kernel_size = weight.size(2)\n",
    "\n",
    "input_feats.shape, weight.shape, bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04fc7a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 6, 24, 24]), torch.Size([6, 3, 5, 5]), torch.Size([6]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import Conv2d\n",
    "\n",
    "conv2d = Conv2d(C_i, C_o, kernel_size, stride=stride, padding=padding, dtype=dtype)\n",
    "\n",
    "conv2d_output = conv2d(input_feats)\n",
    "\n",
    "weight = torch.clone(conv2d.weight)\n",
    "bias = torch.clone(conv2d.bias)\n",
    "\n",
    "conv2d_output.shape, weight.shape, bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c7661f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.nn.functional import fold, unfold\n",
    "\n",
    "# input_feats[0, :, :5, :5][0, 1, 0], unfold(input_feats[0, :, :5, :5], kernel_size)[5, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d0e934c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 75, 576]),\n",
       " torch.Size([6, 75]),\n",
       " torch.Size([64, 6, 576]),\n",
       " torch.Size([64, 6, 24, 24]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.functional import fold, unfold\n",
    "\n",
    "input_unfolded = unfold(input_feats, kernel_size, padding=padding, stride=stride)\n",
    "weight_unfolded = weight.view(C_o, -1)\n",
    "\n",
    "output_unfolded = weight_unfolded @ input_unfolded\n",
    "if bias is not None:\n",
    "    output_unfolded += bias.view(-1, 1)\n",
    "H_o = (H + 2 * padding - kernel_size) // stride + 1\n",
    "output = output_unfolded.view(N, C_o, H_o, -1)\n",
    "\n",
    "input_unfolded.shape, weight_unfolded.shape, output_unfolded.shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34fe99c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "for i, (x, y) in enumerate(zip(output.flatten(), conv2d_output.flatten())):\n",
    "    if not math.isclose(x.item(), y.item()):\n",
    "        print(i, x.item(), y.item())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2399c749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.functional import fold, unfold\n",
    "\n",
    "input_feats = torch.tensor([[[[1, 2], [3, 4]], [[5, 6], [7, 8]]]], dtype=torch.float64)\n",
    "unfold(input_feats, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0928b52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 24)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_o, W_o = output.size(2), output.size(3)\n",
    "\n",
    "H_o, W_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9809b6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 64\n",
    "C_i, C_o = 3, 6\n",
    "H, W = 28, 28\n",
    "K = 5\n",
    "dtype=torch.float64\n",
    "padding = 0\n",
    "stride = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e36a97e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 1\n",
    "# C_i, C_o = 1, 1\n",
    "# H, W = 1, 1\n",
    "# K = 1\n",
    "# dtype=torch.float64\n",
    "# padding = 0\n",
    "# stride = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80731140",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "input_feats = torch.rand((N, C_i, H, W), dtype=dtype)\n",
    "kernel_size = K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "115c1548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Conv2d\n",
    "\n",
    "conv2d = Conv2d(C_i, C_o, kernel_size, padding=padding, stride=stride, dtype=dtype)\n",
    "weight = torch.clone(conv2d.weight)\n",
    "bias = torch.clone(conv2d.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49b02b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[18440.4801, 18469.7358, 18466.8721, 18451.5637, 18451.9761],\n",
       "           [18453.1814, 18475.4890, 18472.2463, 18459.1552, 18455.8155],\n",
       "           [18452.8338, 18479.6673, 18474.2342, 18471.7449, 18469.8156],\n",
       "           [18469.9589, 18493.1058, 18492.5274, 18485.5500, 18482.8736],\n",
       "           [18483.2240, 18503.7942, 18505.1529, 18503.4853, 18501.9564]],\n",
       " \n",
       "          [[18459.0968, 18460.5930, 18454.0254, 18456.0020, 18462.5861],\n",
       "           [18449.8066, 18451.7519, 18449.0025, 18453.2529, 18455.9310],\n",
       "           [18442.6837, 18441.5760, 18429.1081, 18446.9385, 18447.6622],\n",
       "           [18454.9040, 18459.6661, 18451.6285, 18462.9197, 18460.1363],\n",
       "           [18451.6130, 18456.9143, 18454.4624, 18475.3149, 18472.0842]],\n",
       " \n",
       "          [[18411.8377, 18397.1826, 18388.4731, 18391.7583, 18378.3028],\n",
       "           [18403.8543, 18395.1834, 18394.3676, 18391.7302, 18369.1994],\n",
       "           [18380.8593, 18375.9233, 18375.8145, 18370.1944, 18351.2029],\n",
       "           [18364.2336, 18358.7732, 18349.6057, 18348.0267, 18333.5251],\n",
       "           [18371.7708, 18372.8976, 18372.3837, 18368.2352, 18356.6581]]],\n",
       " \n",
       " \n",
       "         [[[18440.4801, 18469.7358, 18466.8721, 18451.5637, 18451.9761],\n",
       "           [18453.1814, 18475.4890, 18472.2463, 18459.1552, 18455.8155],\n",
       "           [18452.8338, 18479.6673, 18474.2342, 18471.7449, 18469.8156],\n",
       "           [18469.9589, 18493.1058, 18492.5274, 18485.5500, 18482.8736],\n",
       "           [18483.2240, 18503.7942, 18505.1529, 18503.4853, 18501.9564]],\n",
       " \n",
       "          [[18459.0968, 18460.5930, 18454.0254, 18456.0020, 18462.5861],\n",
       "           [18449.8066, 18451.7519, 18449.0025, 18453.2529, 18455.9310],\n",
       "           [18442.6837, 18441.5760, 18429.1081, 18446.9385, 18447.6622],\n",
       "           [18454.9040, 18459.6661, 18451.6285, 18462.9197, 18460.1363],\n",
       "           [18451.6130, 18456.9143, 18454.4624, 18475.3149, 18472.0842]],\n",
       " \n",
       "          [[18411.8377, 18397.1826, 18388.4731, 18391.7583, 18378.3028],\n",
       "           [18403.8543, 18395.1834, 18394.3676, 18391.7302, 18369.1994],\n",
       "           [18380.8593, 18375.9233, 18375.8145, 18370.1944, 18351.2029],\n",
       "           [18364.2336, 18358.7732, 18349.6057, 18348.0267, 18333.5251],\n",
       "           [18371.7708, 18372.8976, 18372.3837, 18368.2352, 18356.6581]]],\n",
       " \n",
       " \n",
       "         [[[18440.4801, 18469.7358, 18466.8721, 18451.5637, 18451.9761],\n",
       "           [18453.1814, 18475.4890, 18472.2463, 18459.1552, 18455.8155],\n",
       "           [18452.8338, 18479.6673, 18474.2342, 18471.7449, 18469.8156],\n",
       "           [18469.9589, 18493.1058, 18492.5274, 18485.5500, 18482.8736],\n",
       "           [18483.2240, 18503.7942, 18505.1529, 18503.4853, 18501.9564]],\n",
       " \n",
       "          [[18459.0968, 18460.5930, 18454.0254, 18456.0020, 18462.5861],\n",
       "           [18449.8066, 18451.7519, 18449.0025, 18453.2529, 18455.9310],\n",
       "           [18442.6837, 18441.5760, 18429.1081, 18446.9385, 18447.6622],\n",
       "           [18454.9040, 18459.6661, 18451.6285, 18462.9197, 18460.1363],\n",
       "           [18451.6130, 18456.9143, 18454.4624, 18475.3149, 18472.0842]],\n",
       " \n",
       "          [[18411.8377, 18397.1826, 18388.4731, 18391.7583, 18378.3028],\n",
       "           [18403.8543, 18395.1834, 18394.3676, 18391.7302, 18369.1994],\n",
       "           [18380.8593, 18375.9233, 18375.8145, 18370.1944, 18351.2029],\n",
       "           [18364.2336, 18358.7732, 18349.6057, 18348.0267, 18333.5251],\n",
       "           [18371.7708, 18372.8976, 18372.3837, 18368.2352, 18356.6581]]],\n",
       " \n",
       " \n",
       "         [[[18440.4801, 18469.7358, 18466.8721, 18451.5637, 18451.9761],\n",
       "           [18453.1814, 18475.4890, 18472.2463, 18459.1552, 18455.8155],\n",
       "           [18452.8338, 18479.6673, 18474.2342, 18471.7449, 18469.8156],\n",
       "           [18469.9589, 18493.1058, 18492.5274, 18485.5500, 18482.8736],\n",
       "           [18483.2240, 18503.7942, 18505.1529, 18503.4853, 18501.9564]],\n",
       " \n",
       "          [[18459.0968, 18460.5930, 18454.0254, 18456.0020, 18462.5861],\n",
       "           [18449.8066, 18451.7519, 18449.0025, 18453.2529, 18455.9310],\n",
       "           [18442.6837, 18441.5760, 18429.1081, 18446.9385, 18447.6622],\n",
       "           [18454.9040, 18459.6661, 18451.6285, 18462.9197, 18460.1363],\n",
       "           [18451.6130, 18456.9143, 18454.4624, 18475.3149, 18472.0842]],\n",
       " \n",
       "          [[18411.8377, 18397.1826, 18388.4731, 18391.7583, 18378.3028],\n",
       "           [18403.8543, 18395.1834, 18394.3676, 18391.7302, 18369.1994],\n",
       "           [18380.8593, 18375.9233, 18375.8145, 18370.1944, 18351.2029],\n",
       "           [18364.2336, 18358.7732, 18349.6057, 18348.0267, 18333.5251],\n",
       "           [18371.7708, 18372.8976, 18372.3837, 18368.2352, 18356.6581]]],\n",
       " \n",
       " \n",
       "         [[[18440.4801, 18469.7358, 18466.8721, 18451.5637, 18451.9761],\n",
       "           [18453.1814, 18475.4890, 18472.2463, 18459.1552, 18455.8155],\n",
       "           [18452.8338, 18479.6673, 18474.2342, 18471.7449, 18469.8156],\n",
       "           [18469.9589, 18493.1058, 18492.5274, 18485.5500, 18482.8736],\n",
       "           [18483.2240, 18503.7942, 18505.1529, 18503.4853, 18501.9564]],\n",
       " \n",
       "          [[18459.0968, 18460.5930, 18454.0254, 18456.0020, 18462.5861],\n",
       "           [18449.8066, 18451.7519, 18449.0025, 18453.2529, 18455.9310],\n",
       "           [18442.6837, 18441.5760, 18429.1081, 18446.9385, 18447.6622],\n",
       "           [18454.9040, 18459.6661, 18451.6285, 18462.9197, 18460.1363],\n",
       "           [18451.6130, 18456.9143, 18454.4624, 18475.3149, 18472.0842]],\n",
       " \n",
       "          [[18411.8377, 18397.1826, 18388.4731, 18391.7583, 18378.3028],\n",
       "           [18403.8543, 18395.1834, 18394.3676, 18391.7302, 18369.1994],\n",
       "           [18380.8593, 18375.9233, 18375.8145, 18370.1944, 18351.2029],\n",
       "           [18364.2336, 18358.7732, 18349.6057, 18348.0267, 18333.5251],\n",
       "           [18371.7708, 18372.8976, 18372.3837, 18368.2352, 18356.6581]]],\n",
       " \n",
       " \n",
       "         [[[18440.4801, 18469.7358, 18466.8721, 18451.5637, 18451.9761],\n",
       "           [18453.1814, 18475.4890, 18472.2463, 18459.1552, 18455.8155],\n",
       "           [18452.8338, 18479.6673, 18474.2342, 18471.7449, 18469.8156],\n",
       "           [18469.9589, 18493.1058, 18492.5274, 18485.5500, 18482.8736],\n",
       "           [18483.2240, 18503.7942, 18505.1529, 18503.4853, 18501.9564]],\n",
       " \n",
       "          [[18459.0968, 18460.5930, 18454.0254, 18456.0020, 18462.5861],\n",
       "           [18449.8066, 18451.7519, 18449.0025, 18453.2529, 18455.9310],\n",
       "           [18442.6837, 18441.5760, 18429.1081, 18446.9385, 18447.6622],\n",
       "           [18454.9040, 18459.6661, 18451.6285, 18462.9197, 18460.1363],\n",
       "           [18451.6130, 18456.9143, 18454.4624, 18475.3149, 18472.0842]],\n",
       " \n",
       "          [[18411.8377, 18397.1826, 18388.4731, 18391.7583, 18378.3028],\n",
       "           [18403.8543, 18395.1834, 18394.3676, 18391.7302, 18369.1994],\n",
       "           [18380.8593, 18375.9233, 18375.8145, 18370.1944, 18351.2029],\n",
       "           [18364.2336, 18358.7732, 18349.6057, 18348.0267, 18333.5251],\n",
       "           [18371.7708, 18372.8976, 18372.3837, 18368.2352, 18356.6581]]]],\n",
       "        dtype=torch.float64),\n",
       " tensor([36864., 36864., 36864., 36864., 36864., 36864.], dtype=torch.float64))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.weight.grad, conv2d.bias.grad = None, None\n",
    "conv2d_output = conv2d(input_feats)\n",
    "conv2d_loss = torch.sum(conv2d_output)\n",
    "conv2d_loss.backward()\n",
    "\n",
    "conv2d.weight.grad, conv2d.bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd0df4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 75, 576]),\n",
       " torch.Size([6, 75]),\n",
       " torch.Size([64, 6, 576]),\n",
       " torch.Size([64, 6, 24, 24]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Forward\n",
    "input_unfolded = unfold(input_feats, kernel_size, padding=padding, stride=stride)\n",
    "weight_unfolded = weight.view(C_o, -1)\n",
    "\n",
    "output_unfolded = weight_unfolded @ input_unfolded\n",
    "if bias is not None:\n",
    "    output_unfolded += bias.view(-1, 1)\n",
    "H_o = (H + 2 * padding - kernel_size) // stride + 1\n",
    "output = output_unfolded.view(N, C_o, H_o, -1)\n",
    "\n",
    "input_unfolded.shape, weight_unfolded.shape, output_unfolded.shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc0a2cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check output\n",
    "\n",
    "import math\n",
    "for i, (x, y) in enumerate(zip(output.flatten(), conv2d_output.flatten())):\n",
    "    if not math.isclose(x.item(), y.item()):\n",
    "        print(i, x.item(), y.item())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7052aeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_input_unfolded.shape=torch.Size([64, 75, 576])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 6, 576]),\n",
       " torch.Size([64, 576, 75]),\n",
       " torch.Size([64, 6, 75]),\n",
       " torch.Size([6, 192, 5, 5]),\n",
       " torch.Size([6]),\n",
       " torch.Size([64, 75, 576]),\n",
       " torch.Size([64, 3, 28, 28]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Backward\n",
    "\n",
    "from torch.nn.functional import fold, unfold\n",
    "\n",
    "H_o, W_o = output.size(2), output.size(3)\n",
    "grad_output = torch.ones(N, C_o, H_o, W_o, dtype=dtype)\n",
    "grad_output_unfolded = grad_output.view(N, C_o, -1)\n",
    "input_transpose = torch.transpose(input_unfolded, 1, 2)\n",
    "\n",
    "grad_weight_unfolded = grad_output_unfolded @ input_transpose\n",
    "grad_weight = grad_weight_unfolded.view(C_o, -1, kernel_size, kernel_size)\n",
    "\n",
    "if bias is not None:\n",
    "    grad_bias = grad_output.sum((0, 2, 3))\n",
    "    \n",
    "grad_input_unfolded = weight_unfolded.T @ grad_output_unfolded\n",
    "print(f'{grad_input_unfolded.shape=}')\n",
    "grad_input = fold(grad_input_unfolded, (H, W), kernel_size, padding=padding, stride=stride)\n",
    "\n",
    "grad_output_unfolded.shape, input_transpose.shape, grad_weight_unfolded.shape, grad_weight.shape, grad_bias.shape, grad_input_unfolded.shape, grad_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd62ea92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[276.0759, 278.1814, 285.5806, 287.2416, 288.8733],\n",
       "           [277.9637, 279.8928, 287.4910, 287.9858, 288.9815],\n",
       "           [279.9336, 281.8117, 288.8646, 289.0004, 289.6573],\n",
       "           [280.5021, 281.5903, 289.2209, 289.1159, 289.7964],\n",
       "           [280.0599, 280.7586, 288.6812, 288.3911, 290.5463]],\n",
       " \n",
       "          [[287.7494, 289.1279, 286.9570, 287.2503, 286.8624],\n",
       "           [287.7234, 290.4687, 287.5817, 287.1176, 288.0064],\n",
       "           [289.0962, 291.7841, 289.5663, 290.2381, 291.2292],\n",
       "           [287.9945, 290.8185, 289.9709, 289.9607, 290.6809],\n",
       "           [287.9319, 291.9899, 291.2869, 290.8627, 291.4758]],\n",
       " \n",
       "          [[289.4086, 290.2703, 289.5732, 293.1443, 294.2315],\n",
       "           [291.6795, 292.2767, 292.4964, 296.2032, 297.1850],\n",
       "           [294.8090, 295.8031, 297.1219, 300.4963, 301.7813],\n",
       "           [292.2125, 292.7680, 293.8412, 298.4244, 298.8863],\n",
       "           [290.5545, 291.9364, 293.0503, 297.6583, 298.9564]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[279.7469, 278.6843, 277.1249, 272.5242, 274.9350],\n",
       "           [280.6147, 279.2517, 277.8527, 272.9101, 275.3292],\n",
       "           [281.3607, 280.3893, 278.6810, 274.1206, 275.8438],\n",
       "           [280.9982, 280.5813, 279.5592, 274.1575, 276.3827],\n",
       "           [286.2289, 285.1953, 284.8092, 279.4395, 280.7395]],\n",
       " \n",
       "          [[284.4281, 281.2230, 282.2618, 282.3103, 281.7820],\n",
       "           [282.2491, 278.4869, 279.9752, 280.6797, 281.0375],\n",
       "           [280.3711, 276.7159, 277.9297, 279.2858, 278.5463],\n",
       "           [282.5037, 279.5712, 281.0913, 283.1869, 281.7201],\n",
       "           [283.5031, 281.3908, 282.7126, 284.5966, 283.1124]],\n",
       " \n",
       "          [[293.0887, 295.8553, 292.1548, 292.7287, 293.1281],\n",
       "           [293.4174, 296.2892, 293.1357, 293.9777, 294.2133],\n",
       "           [294.0252, 297.0691, 293.1614, 293.4919, 293.5819],\n",
       "           [290.7544, 294.1347, 290.2245, 290.6882, 290.7353],\n",
       "           [288.0606, 291.9760, 288.0097, 288.3035, 288.7672]]],\n",
       " \n",
       " \n",
       "         [[[279.7469, 278.6843, 277.1249, 272.5242, 274.9350],\n",
       "           [280.6147, 279.2517, 277.8527, 272.9101, 275.3292],\n",
       "           [281.3607, 280.3893, 278.6810, 274.1206, 275.8438],\n",
       "           [280.9982, 280.5813, 279.5592, 274.1575, 276.3827],\n",
       "           [286.2289, 285.1953, 284.8092, 279.4395, 280.7395]],\n",
       " \n",
       "          [[284.4281, 281.2230, 282.2618, 282.3103, 281.7820],\n",
       "           [282.2491, 278.4869, 279.9752, 280.6797, 281.0375],\n",
       "           [280.3711, 276.7159, 277.9297, 279.2858, 278.5463],\n",
       "           [282.5037, 279.5712, 281.0913, 283.1869, 281.7201],\n",
       "           [283.5031, 281.3908, 282.7126, 284.5966, 283.1124]],\n",
       " \n",
       "          [[293.0887, 295.8553, 292.1548, 292.7287, 293.1281],\n",
       "           [293.4174, 296.2892, 293.1357, 293.9777, 294.2133],\n",
       "           [294.0252, 297.0691, 293.1614, 293.4919, 293.5819],\n",
       "           [290.7544, 294.1347, 290.2245, 290.6882, 290.7353],\n",
       "           [288.0606, 291.9760, 288.0097, 288.3035, 288.7672]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[289.1308, 288.6049, 288.6193, 289.2266, 286.2993],\n",
       "           [288.3203, 288.3434, 288.9228, 288.5761, 287.0045],\n",
       "           [284.9162, 284.3607, 284.8390, 285.8556, 284.7182],\n",
       "           [285.6120, 284.3490, 284.9105, 285.2916, 284.3528],\n",
       "           [285.8536, 284.6773, 284.2826, 284.8965, 285.1767]],\n",
       " \n",
       "          [[285.1549, 281.8879, 280.9125, 279.3408, 279.4144],\n",
       "           [285.1678, 282.1150, 282.0889, 280.3622, 280.5450],\n",
       "           [284.8544, 281.1312, 280.9414, 279.6776, 279.1226],\n",
       "           [283.8291, 281.1099, 280.6279, 279.6841, 279.3977],\n",
       "           [283.4312, 280.8538, 280.6827, 279.1293, 278.6491]],\n",
       " \n",
       "          [[277.7711, 278.3369, 274.9265, 275.0088, 275.2521],\n",
       "           [276.3302, 277.5611, 274.6757, 274.4281, 274.3217],\n",
       "           [275.1029, 276.9072, 273.5726, 273.5737, 274.0128],\n",
       "           [271.0542, 272.4614, 268.9863, 270.0170, 271.1614],\n",
       "           [269.8662, 271.4768, 267.8446, 269.7354, 269.7154]]],\n",
       " \n",
       " \n",
       "         [[[289.1308, 288.6049, 288.6193, 289.2266, 286.2993],\n",
       "           [288.3203, 288.3434, 288.9228, 288.5761, 287.0045],\n",
       "           [284.9162, 284.3607, 284.8390, 285.8556, 284.7182],\n",
       "           [285.6120, 284.3490, 284.9105, 285.2916, 284.3528],\n",
       "           [285.8536, 284.6773, 284.2826, 284.8965, 285.1767]],\n",
       " \n",
       "          [[285.1549, 281.8879, 280.9125, 279.3408, 279.4144],\n",
       "           [285.1678, 282.1150, 282.0889, 280.3622, 280.5450],\n",
       "           [284.8544, 281.1312, 280.9414, 279.6776, 279.1226],\n",
       "           [283.8291, 281.1099, 280.6279, 279.6841, 279.3977],\n",
       "           [283.4312, 280.8538, 280.6827, 279.1293, 278.6491]],\n",
       " \n",
       "          [[277.7711, 278.3369, 274.9265, 275.0088, 275.2521],\n",
       "           [276.3302, 277.5611, 274.6757, 274.4281, 274.3217],\n",
       "           [275.1029, 276.9072, 273.5726, 273.5737, 274.0128],\n",
       "           [271.0542, 272.4614, 268.9863, 270.0170, 271.1614],\n",
       "           [269.8662, 271.4768, 267.8446, 269.7354, 269.7154]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[296.0953, 296.8948, 298.0661, 298.7486, 302.0007],\n",
       "           [294.5629, 294.5981, 295.5743, 295.7852, 299.1438],\n",
       "           [293.3695, 292.4174, 293.3853, 294.0880, 297.7756],\n",
       "           [289.4713, 287.7980, 288.9610, 290.1779, 292.1735],\n",
       "           [290.5770, 288.9888, 288.9204, 289.7572, 291.5808]],\n",
       " \n",
       "          [[282.5763, 283.0818, 283.8190, 286.1494, 287.4892],\n",
       "           [281.7918, 282.7314, 283.3040, 284.9882, 286.5274],\n",
       "           [281.8804, 282.8752, 283.0800, 285.8545, 286.6386],\n",
       "           [283.3749, 284.0400, 284.0937, 285.9656, 285.7731],\n",
       "           [286.5188, 287.8094, 286.6677, 288.6104, 288.9845]],\n",
       " \n",
       "          [[293.3283, 294.9744, 292.2446, 288.2726, 290.5555],\n",
       "           [291.7682, 293.7094, 291.0956, 286.9602, 289.1397],\n",
       "           [293.4614, 294.8736, 291.6951, 287.3375, 289.2710],\n",
       "           [293.7241, 295.5070, 291.9047, 286.7794, 289.2778],\n",
       "           [293.1715, 295.7213, 292.3423, 286.6568, 288.8770]]],\n",
       " \n",
       " \n",
       "         [[[288.1724, 290.3591, 288.1892, 290.6789, 288.4941],\n",
       "           [284.7139, 286.9507, 285.9134, 288.2983, 286.3533],\n",
       "           [288.1153, 290.2635, 289.3195, 291.6969, 289.7525],\n",
       "           [288.9115, 291.5886, 290.5031, 292.8604, 290.9742],\n",
       "           [287.3917, 290.2739, 289.7374, 291.8197, 289.6638]],\n",
       " \n",
       "          [[282.5121, 280.3693, 276.4829, 278.6957, 278.8207],\n",
       "           [284.8217, 283.0986, 279.7532, 281.6063, 282.7431],\n",
       "           [287.1389, 285.5013, 282.8237, 284.5281, 286.0074],\n",
       "           [288.7956, 286.8681, 283.2458, 284.6061, 286.3755],\n",
       "           [288.4397, 286.6811, 282.8726, 283.6604, 284.7931]],\n",
       " \n",
       "          [[289.1328, 288.3622, 287.5664, 287.1865, 286.9792],\n",
       "           [287.4660, 287.3656, 286.5747, 287.0570, 287.3687],\n",
       "           [287.5760, 286.3641, 284.7649, 284.9376, 285.5271],\n",
       "           [287.7817, 286.6281, 285.0068, 285.0961, 284.9022],\n",
       "           [289.2987, 288.1123, 287.1749, 286.0551, 286.1231]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[273.4601, 271.5253, 271.1199, 273.2954, 273.5485],\n",
       "           [271.4395, 269.4038, 269.1287, 271.4140, 271.2425],\n",
       "           [271.6779, 269.1118, 269.0899, 271.9019, 273.1862],\n",
       "           [272.6887, 270.0295, 269.8017, 272.8437, 274.0567],\n",
       "           [272.9686, 269.7532, 269.6559, 272.6486, 272.8821]],\n",
       " \n",
       "          [[296.0797, 297.1859, 298.1575, 302.2380, 304.3984],\n",
       "           [294.4616, 294.3101, 295.5580, 299.1419, 302.3058],\n",
       "           [294.2964, 295.4927, 296.3961, 300.0360, 303.5894],\n",
       "           [293.3832, 294.7829, 294.9461, 298.5143, 301.8577],\n",
       "           [290.1553, 292.1845, 292.2688, 296.1100, 299.8083]],\n",
       " \n",
       "          [[284.3664, 285.0002, 286.4848, 285.6350, 289.4846],\n",
       "           [283.2112, 283.4732, 284.7587, 282.7892, 286.0248],\n",
       "           [281.8936, 281.8287, 283.2858, 281.6219, 285.0906],\n",
       "           [281.0856, 281.1967, 281.2973, 278.3909, 280.7773],\n",
       "           [280.4486, 280.7281, 281.3003, 278.7597, 281.2849]]],\n",
       " \n",
       " \n",
       "         [[[273.4601, 271.5253, 271.1199, 273.2954, 273.5485],\n",
       "           [271.4395, 269.4038, 269.1287, 271.4140, 271.2425],\n",
       "           [271.6779, 269.1118, 269.0899, 271.9019, 273.1862],\n",
       "           [272.6887, 270.0295, 269.8017, 272.8437, 274.0567],\n",
       "           [272.9686, 269.7532, 269.6559, 272.6486, 272.8821]],\n",
       " \n",
       "          [[296.0797, 297.1859, 298.1575, 302.2380, 304.3984],\n",
       "           [294.4616, 294.3101, 295.5580, 299.1419, 302.3058],\n",
       "           [294.2964, 295.4927, 296.3961, 300.0360, 303.5894],\n",
       "           [293.3832, 294.7829, 294.9461, 298.5143, 301.8577],\n",
       "           [290.1553, 292.1845, 292.2688, 296.1100, 299.8083]],\n",
       " \n",
       "          [[284.3664, 285.0002, 286.4848, 285.6350, 289.4846],\n",
       "           [283.2112, 283.4732, 284.7587, 282.7892, 286.0248],\n",
       "           [281.8936, 281.8287, 283.2858, 281.6219, 285.0906],\n",
       "           [281.0856, 281.1967, 281.2973, 278.3909, 280.7773],\n",
       "           [280.4486, 280.7281, 281.3003, 278.7597, 281.2849]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[282.6337, 284.3144, 283.8421, 284.5999, 286.6723],\n",
       "           [281.3722, 282.7161, 281.8424, 283.5546, 285.6868],\n",
       "           [282.4310, 284.3134, 283.0630, 285.0267, 287.7881],\n",
       "           [284.3110, 286.0691, 285.3827, 286.6514, 289.1138],\n",
       "           [284.0975, 286.1556, 286.5317, 287.8080, 290.4967]],\n",
       " \n",
       "          [[297.9724, 297.2369, 299.3424, 295.4015, 293.4694],\n",
       "           [299.3851, 298.1672, 300.6821, 297.5631, 295.7261],\n",
       "           [301.0722, 299.9732, 302.2820, 298.5762, 296.9609],\n",
       "           [302.6227, 301.7871, 303.6723, 300.3071, 298.9748],\n",
       "           [305.1312, 304.5523, 306.6371, 303.4650, 301.4905]],\n",
       " \n",
       "          [[300.0289, 300.6830, 301.0203, 303.1892, 302.2680],\n",
       "           [298.8095, 300.2299, 299.2199, 300.8358, 300.7173],\n",
       "           [299.1299, 299.3932, 298.9651, 299.4622, 300.1846],\n",
       "           [298.9815, 299.1571, 298.2337, 298.9656, 299.4077],\n",
       "           [299.3315, 299.0205, 298.5524, 298.8358, 299.6940]]],\n",
       " \n",
       " \n",
       "         [[[282.6337, 284.3144, 283.8421, 284.5999, 286.6723],\n",
       "           [281.3722, 282.7161, 281.8424, 283.5546, 285.6868],\n",
       "           [282.4310, 284.3134, 283.0630, 285.0267, 287.7881],\n",
       "           [284.3110, 286.0691, 285.3827, 286.6514, 289.1138],\n",
       "           [284.0975, 286.1556, 286.5317, 287.8080, 290.4967]],\n",
       " \n",
       "          [[297.9724, 297.2369, 299.3424, 295.4015, 293.4694],\n",
       "           [299.3851, 298.1672, 300.6821, 297.5631, 295.7261],\n",
       "           [301.0722, 299.9732, 302.2820, 298.5762, 296.9609],\n",
       "           [302.6227, 301.7871, 303.6723, 300.3071, 298.9748],\n",
       "           [305.1312, 304.5523, 306.6371, 303.4650, 301.4905]],\n",
       " \n",
       "          [[300.0289, 300.6830, 301.0203, 303.1892, 302.2680],\n",
       "           [298.8095, 300.2299, 299.2199, 300.8358, 300.7173],\n",
       "           [299.1299, 299.3932, 298.9651, 299.4622, 300.1846],\n",
       "           [298.9815, 299.1571, 298.2337, 298.9656, 299.4077],\n",
       "           [299.3315, 299.0205, 298.5524, 298.8358, 299.6940]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[292.5903, 293.9966, 291.7129, 290.7874, 291.7581],\n",
       "           [290.6344, 292.0487, 290.6501, 290.1193, 290.7260],\n",
       "           [293.1933, 294.0638, 292.3983, 291.9918, 292.7687],\n",
       "           [292.0797, 292.9548, 290.6301, 289.7490, 290.9620],\n",
       "           [294.1551, 294.4417, 293.5583, 292.4553, 293.9423]],\n",
       " \n",
       "          [[288.8032, 287.8833, 288.1199, 287.0160, 284.8944],\n",
       "           [290.9560, 289.0161, 289.3884, 289.1443, 286.4544],\n",
       "           [290.8995, 288.4173, 288.8764, 289.8917, 287.6618],\n",
       "           [293.1511, 290.2225, 291.0269, 291.3033, 289.4418],\n",
       "           [292.0575, 289.6682, 291.0698, 291.7354, 289.0662]],\n",
       " \n",
       "          [[289.6363, 286.7041, 291.8286, 291.2040, 288.8256],\n",
       "           [287.2248, 285.1344, 290.9671, 289.9729, 287.6685],\n",
       "           [284.1076, 282.0304, 288.0934, 287.4594, 285.5351],\n",
       "           [284.6711, 283.4962, 290.1655, 289.0719, 287.3422],\n",
       "           [284.9502, 284.2015, 290.9395, 289.5392, 287.9862]]]],\n",
       "        dtype=torch.float64),\n",
       " tensor([36864., 36864., 36864., 36864., 36864., 36864.], dtype=torch.float64))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grad_weight, grad_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ed0136fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup and settings\n",
    "\n",
    "N = 64\n",
    "C_i, C_o = 3, 6\n",
    "H, W = 32, 32\n",
    "K = 5\n",
    "dtype=torch.float64\n",
    "padding = 0\n",
    "stride = 1\n",
    "\n",
    "torch.manual_seed(42)\n",
    "input_feats = torch.rand((N, C_i, H, W), dtype=dtype)\n",
    "kernel_size = K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bc382d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Conv2d\n",
    "\n",
    "conv2d = Conv2d(C_i, C_o, kernel_size, padding=padding, stride=stride, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2d736244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from student_code import CustomConv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "37f81743",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_conv2d = Conv2d(C_i, C_o, kernel_size, padding=padding, stride=stride, dtype=dtype)\n",
    "custom_conv2d.weight = nn.Parameter(conv2d.weight.clone())\n",
    "custom_conv2d.bias = nn.Parameter(conv2d.bias.clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aa98cbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0556, dtype=torch.float64, grad_fn=<MeanBackward0>),\n",
       " tensor(25092.5053, dtype=torch.float64))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Forward and backward pass (vanilla)\n",
    "\n",
    "conv2d_output = conv2d(input_feats)\n",
    "loss = torch.sum(conv2d_output)\n",
    "loss.backward()\n",
    "\n",
    "torch.mean(conv2d_output), torch.mean(conv2d.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3a144a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0556, dtype=torch.float64, grad_fn=<MeanBackward0>),\n",
       " tensor(25092.5053, dtype=torch.float64))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Forward and backward pass (custom)\n",
    "\n",
    "custom_conv2d_output = custom_conv2d(input_feats)\n",
    "custom_loss = torch.sum(custom_conv2d_output)\n",
    "custom_loss.backward()\n",
    "\n",
    "torch.mean(custom_conv2d_output), torch.mean(custom_conv2d.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66866b45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
